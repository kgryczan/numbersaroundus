[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numbers Around Us",
    "section": "",
    "text": "Welcome to Numbers Around Us, your go-to resource for mastering analytics programming, business intelligence tools, and the art of data-driven thinking. Whether you’re diving into R, Python, or SQL, exploring Tableau and Power BI, or rethinking how you approach data projects, you’ll find practical insights, tools, and solutions here."
  },
  {
    "objectID": "index.html#what-you-will-find",
    "href": "index.html#what-you-will-find",
    "title": "Numbers Around Us",
    "section": "What You Will Find",
    "text": "What You Will Find\n\n1. Analytics Programming (R, SQL, Python)\nUnlock the potential of your data with step-by-step tutorials, advanced tips, and innovative solutions. Our resources cover:\n\nR: From data wrangling to advanced visualizations, learn how to harness the power of R.\nPython: Explore its versatility, from automation to machine learning.\nSQL: Master the language of databases for efficient querying and analysis.\n\n\n\n2. Business Intelligence (Tableau and Power BI)\nVisualize and communicate your insights effectively. Learn how to:\n\nCreate stunning dashboards and reports in Tableau.\nBuild dynamic, actionable visuals in Power BI.\nIntegrate BI tools into your analytics workflow.\n\n\n\n3. Data Philosophy\nAnalytics is more than tools—it’s a mindset. In this section, we explore:\n\nData management: Best practices for clean and reliable data.\nProject planning: Strategies for successful analytics projects.\nEthics and governance: Ensuring responsible use of data."
  },
  {
    "objectID": "index.html#solve-challenges-gain-insights",
    "href": "index.html#solve-challenges-gain-insights",
    "title": "Numbers Around Us",
    "section": "Solve Challenges, Gain Insights",
    "text": "Solve Challenges, Gain Insights\nOne of our standout features is our Challenge Solutions section. Here, we tackle real-world analytics challenges from LinkedIn, offering:\n\nDetailed solutions in R and Python.\nInsights into problem-solving techniques.\nTips for applying these skills to your own work."
  },
  {
    "objectID": "index.html#why-choose-numbers-around-us",
    "href": "index.html#why-choose-numbers-around-us",
    "title": "Numbers Around Us",
    "section": "Why Choose Numbers Around Us?",
    "text": "Why Choose Numbers Around Us?\nWe combine technical expertise with a passion for data-driven storytelling. Whether you’re a beginner looking for guidance or an experienced analyst refining your craft, our content is designed to inspire and empower you.\n\nStart Your Journey\nDive into our latest articles, explore the challenge solutions, or check out the Data Philosophy section to rethink how you work with data. Let’s build a smarter, more insightful data world—together."
  },
  {
    "objectID": "bi/posts/2024-04-11_Crafting-Elegant-Scientific-Documents-in-RStudio--A-LaTeX-and-R-Markdown-Tutorial-a5b788d8a38d.html",
    "href": "bi/posts/2024-04-11_Crafting-Elegant-Scientific-Documents-in-RStudio--A-LaTeX-and-R-Markdown-Tutorial-a5b788d8a38d.html",
    "title": "Crafting Elegant Scientific Documents in RStudio: A LaTeX and R Markdown Tutorial",
    "section": "",
    "text": "Image\n\n\n\nIntroduction\nIn the world of scientific research and academic writing, the clarity, precision, and aesthetics of your documents can significantly impact their reception and comprehension. LaTeX, a powerful typesetting system, has long been revered for its ability to create beautifully formatted documents, especially those requiring complex mathematical expressions and detailed layouts. However, the steep learning curve associated with LaTeX can deter many. Enter R Markdown, a tool that simplifies the creation of dynamic documents, presentations, and reports directly from R code. When combined with the versatility of RStudio, it offers a more accessible entry point into the world of LaTeX, without sacrificing the depth and precision that professional documents require.\nThis tutorial aims to bridge the gap between the high-quality typesetting capabilities of LaTeX and the dynamic, code-integrated documentation of R Markdown. Whether you’re compiling research findings, drafting an academic paper, or preparing a report with rich data visualizations, integrating LaTeX with R Markdown in RStudio enhances both the appearance and functionality of your work. By the end of this guide, you’ll be equipped with the knowledge to leverage the best of both worlds, crafting documents that stand out for their elegance and precision.\n\n\nPrerequisites and Setup\n\nInstalling RStudio and LaTeX\nBefore we dive into the intricacies of combining LaTeX with R Markdown, let’s ensure you have all the necessary tools installed. RStudio is an indispensable IDE for anyone working with R, and it provides seamless support for R Markdown. LaTeX, on the other hand, is a typesetting system that excels in document preparation, especially for those containing complex mathematical formulas.\n\nRStudio: If you haven’t already, download and install RStudio. Choose the version appropriate for your operating system.\nLaTeX Distribution: For LaTeX, you need a distribution based on your operating system. Windows users can opt for MiKTeX, macOS users for MacTeX, and Linux users for TeX Live. Installation links and instructions are readily available on their respective websites.\n\nAfter installing both RStudio and your LaTeX distribution, ensure that RStudio can locate your LaTeX installation. This integration is typically automatic, but you can verify or adjust the settings in RStudio by navigating to Tools &gt; Global Options &gt; Sweave.\n\n\nConfiguring RStudio for LaTeX and R Markdown\nWith RStudio and LaTeX installed, the next step is to configure your RStudio environment for an optimal working experience. This involves:\n\nInstalling Necessary R Packages: Open RStudio and install the rmarkdown package, which supports the integration of R code with Markdown (and by extension, LaTeX) for dynamic document generation. Install it by running:\n\ninstall.packages(\"rmarkdown\")\n\nTesting Your Setup: To confirm everything is set up correctly, create a new R Markdown document. Go to File &gt; New File &gt; R Markdown…, then choose PDF as the output format. This action requires LaTeX for PDF generation, so if it succeeds without errors, your setup is correct.\n\nThis section’s goal is to ensure you have a smooth start with all the necessary tools at your disposal. Once you’re set up, the real fun begins: exploring the synergy between LaTeX and R Markdown to create stunning scientific documents.\n\n\n\nYour First R Markdown Document with LaTeX\nCreating your first R Markdown document integrated with LaTeX in RStudio is a simple yet exciting process. This section will guide you through creating a basic document, adding LaTeX for formatting and equations, and generating a PDF output.\n\nCreating an R Markdown Document\n\nStart a New R Markdown File: In RStudio, go to File &gt; New File &gt; R Markdown… This opens a dialog where you can set the document’s title and output format. For now, select PDF and click OK.\nExplore the Default Content: RStudio will generate a sample document filled with some basic Markdown content and example code chunks. This template serves as an excellent introduction to R Markdown’s capabilities.\n\n\n\nIntegrating Basic LaTeX Elements\nWithin your R Markdown document, you can start integrating LaTeX directly. Here’s how you can add some basic LaTeX commands for text formatting and sections:\nThis is an R Markdown document with \\LaTeX. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, which then converts to \\LaTeX for high-quality document production.\n\n\\section{Introduction}\nThis is a section created using LaTeX.\n\n\\subsection{Background}\nThis subsection provides background information, also formatted using LaTeX.\n\n\\textbf{Bold text} and \\textit{italicized text} can easily be added with LaTeX commands.\n\n\nAdding Mathematical Expressions\nOne of LaTeX’s strengths is its ability to format complex mathematical expressions beautifully. In R Markdown, you can include these expressions by enclosing them in dollar signs for inline equations or double dollar signs for displayed equations:\nHere is an inline equation: \\(E=mc^2\\).\n\nAnd a displayed equation:\n\n$$\na^2 + b^2 = c^2\n$$\n\n\nCompiling to PDF\nAfter adding your content, compile the document to PDF by clicking the “Knit” button in RStudio and selecting PDF. RStudio will use LaTeX to process your document, incorporating any LaTeX commands or mathematical expressions you’ve included, and generate a PDF.\n\n\n\nImage\n\n\nThis simple exercise demonstrates the power of combining R Markdown’s dynamic capabilities with LaTeX’s typesetting prowess, all within the RStudio environment. Whether you’re documenting research findings, drafting a paper, or preparing a report, this approach allows you to create professional, elegantly formatted documents efficiently.\n\n\n\nAdvanced LaTeX Features in R Markdown\nHaving grasped the basics of integrating LaTeX into R Markdown documents, we’ll now delve into advanced features to further elevate your scientific document’s quality. This segment highlights enhanced figure and table management, utilizing custom LaTeX commands, and effectively handling bibliographies within RStudio.\n\nWorking with Figures and Tables\nLaTeX is renowned for its precise control over figures and tables, but in R Markdown, we approach these elements differently, leveraging Markdown and R code chunks for dynamic content integration and formatting.\nFigures\nFor static images, use Markdown syntax:\n![Caption for the figure.](my_address_to_logo){width=20%}\nFor dynamically generated figures from R:\n{r label, echo=FALSE, fig.cap=\"Caption for the figure.\"}\ndata(mtcars)\nplot(mtcars$wt, mtcars$mpg)\n\n\n\nImage\n\n\nTables\nTo create detailed and customizable tables in your R Markdown document using LaTeX, you’ll directly use the tabular environment provided by LaTeX. This allows for precise control over the table’s appearance, alignment, and overall structure. Here’s a basic example of creating a table with LaTeX:\n\\begin{table}[h]\n\\centering\n\\caption{Sample Data Table}\n\\begin{tabular}{lcr}\n\\hline\n\\textbf{Left Align} & \\textbf{Center} & \\textbf{Right Align} \\\\\n\\hline\nData 1 & Data 2 & Data 3 \\\\\nMore & Data & Here \\\\\n\\hline\n\\end{tabular}\n\\label{tab:sample_table}\n\\end{table}\nThis LaTeX code snippet places a table with headers aligned to the left, center, and right. The \\hline command creates horizontal lines for clarity, and \\textbf is used for bold header text. The \\caption{} and \\label{} commands are used for the table’s caption and referencing it in the text, respectively.\n\n\nDefining and Using Custom LaTeX Commands\nYou can define custom LaTeX commands for repetitive tasks or to simplify complex formatting. Custom commands are defined in the YAML header of your R Markdown document using header-includes:\nheader-includes:\n  - \\newcommand{\\highlight}[1]{\\textbf{\\textcolor{red}{#1}}}\nThis command, \\highlight{}, makes specified text bold and red. To use this command within your document:\nThis is regular text and this is \\highlight{highlighted text}.\n\n\nApplying Custom Commands in Tables\nYour custom LaTeX commands can be utilized within tables to emphasize specific pieces of data or apply consistent formatting. Using the previously defined \\highlight{} command:\n\\begin{table}[h]\n\\centering\n\\caption{Demonstrating Custom Commands in Tables}\n\\begin{tabular}{lc}\n\\hline\n\\textbf{Description} & \\textbf{Data} \\\\\n\\hline\nRegular Data & 123 \\\\\nHighlighted Data & \\highlight{456} \\\\\n\\hline\n\\end{tabular}\n\\label{tab:custom_command_table}\n\\end{table}\nThis example shows how to apply the \\highlight{} command within a table to make specific data stand out.\n\n\n\nImage\n\n\nIn this chapter, we’ve explored how to enhance your R Markdown documents with figures and sophisticated table formatting using LaTeX and the creation and application of custom LaTeX commands. Starting with the tabular environment, we demonstrated the method to craft detailed tables that meet specific aesthetic and structural requirements. Additionally, we covered how to define and utilize custom LaTeX commands within your document, allowing for efficient and consistent formatting across your scientific documents. This approach ensures that your work not only conveys information effectively but also adheres to the high standards of professional and academic presentation.\n\n\n\nCrafting Complex Scientific Equations with LaTeX in R Markdown\nThe seamless integration of LaTeX within R Markdown particularly shines when dealing with complex scientific equations, which are cumbersome, if not impossible, to accurately represent in plain text or basic Markdown. LaTeX provides a comprehensive set of tools for typesetting mathematical expressions, from simple fractions to elaborate equations used in advanced physics and mathematics. This chapter demonstrates how to leverage LaTeX for this purpose within an R Markdown document.\n\nBasic Mathematical Expressions\nLaTeX allows for the inline and block display of mathematical expressions. For inline equations, enclose your LaTeX code in single dollar signs ($), and for equations that should be displayed as a separate block, use double dollar signs ($$).\nInline Equation:\nEinstein's famous equation can be represented inline as $E=mc^2$.\nDisplayed Equation:\n$$E=mc^2$$\nThis displays the equation centered on its own line, making it stand out for emphasis.\n\n\nAdvanced Equation Formatting\nLaTeX excels in formatting complex equations, such as systems of equations, matrices, and functions involving sums, integrals, and limits.\nSystem of Equations:\n$$\n\\begin{align*}\nx + y &= 10 \\\\\n2x - y &= 4\n\\end{align*}\n$$\nMatrix:\n$$\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n$$\nIntegral:\n$$\n\\int_0^\\infty e^{-x}dx\n$$\nThese examples demonstrate just a fraction of the capabilities LaTeX offers for mathematical typesetting. When utilized within R Markdown, it enables authors to seamlessly integrate complex mathematical content into their documents, enhancing both readability and professionalism.\n\n\nUtilizing LaTeX for Scientific Notation\nScientific documents often require notation that is difficult or awkward to express in other formats. LaTeX addresses this with a broad array of symbols and structures designed specifically for scientific writing:\n$$\n\\gamma + \\pi \\approx 3.14 \\text{, where } \\gamma \\text{ is the Euler-Mascheroni constant, and } \\pi \\text{ is the mathematical constant pi.}\n$$\nThe combination of R Markdown and LaTeX provides a powerful toolset for scientists, mathematicians, and anyone else working with complex equations or scientific notation. It brings together the best of both worlds: the dynamism and reproducibility of R Markdown with the precise typesetting and extensive capabilities of LaTeX.\n\n\nSome more complex equations\nFourier Series:\n$$\nf(x) = a_0 + \\sum_{n=1}^{\\infty} \\left( a_n \\cos \\frac{2\\pi nx}{P} + b_n \\sin \\frac{2\\pi nx}{P} \\right)\n$$\nSchrodinger equation:\n$$\ni\\hbar\\frac{\\partial}{\\partial t}\\Psi(\\mathbf{r}, t) = \\left[ \\frac{-\\hbar^2}{2\\mu}\\nabla^2 + V(\\mathbf{r}, t) \\right] \\Psi(\\mathbf{r}, t)\n$$\nGeneral relativity field equation:\n$$\nG_{\\mu\\nu} + \\Lambda g_{\\mu\\nu} = \\frac{8\\pi G}{c^4} T_{\\mu\\nu}\n$$\nNavier-Stokes Equations for Fluid Dynamics:\n$$\n\\rho \\left( \\frac{\\partial \\mathbf{v}}{\\partial t} + \\mathbf{v} \\cdot \\nabla \\mathbf{v} \\right) = -\\nabla p + \\mu \\nabla^2 \\mathbf{v} + \\mathbf{f}\n$$\nAnd render of all equations included in chapter.\n\n\n\nImage\n\n\n\n\n\nCompiling Documents and Customizing Outputs in R Markdown\nR Markdown provides a seamless workflow for creating dynamic documents, reports, presentations, and more, directly from R. When incorporating LaTeX, you gain additional control over the document’s appearance, enabling the creation of professional-grade scientific documents. This chapter explores how to compile your R Markdown documents into PDFs, leveraging LaTeX for advanced formatting, and how to customize these outputs to fit various academic and professional standards.\n\nCompiling R Markdown Documents to PDF\nTo compile an R Markdown document to PDF with LaTeX formatting:\n\nEnsure LaTeX is Installed: Before compiling, make sure you have a LaTeX distribution installed on your computer, as discussed in the setup chapter.\nUse the ‘Knit’ Button: In RStudio, the simplest way to compile your document is by using the Knit button. When you click Knit, RStudio automatically renders your document into a PDF, incorporating any LaTeX code or styling you’ve included.\nCustomizing the Build Process: For more control over the compilation process, you can use the rmarkdown::render() function in the R console:\n\nrmarkdown::render(\"your_document.Rmd\", output_format = \"pdf_document\")\nThis function allows for additional arguments and customization, offering more flexibility than the Knit button.\n\n\nCustomizing PDF Output with LaTeX\nLaTeX allows for extensive customization of PDF output through the use of packages and settings defined in the preamble of your R Markdown document. Here are a few ways to customize your PDF documents:\n\nPage Layout and Fonts: Use LaTeX packages such as geometry to adjust margins, fancyhdr for custom headers and footers, and fontspec for font customization.\n\nheader-includes:\n  - \\usepackage{geometry}\n  - \\geometry{left=3cm,right=3cm,top=2cm,bottom=2cm}\n  - \\usepackage{fancyhdr}\n  - \\pagestyle{fancy}\n  - \\usepackage{fontspec}\n  - \\setmainfont{Times New Roman}\n\nSection Formatting: Customize section titles using the titlesec package.\n\nheader-includes:\n  - \\usepackage{titlesec}\n  - \\titleformat*{\\section}{\\Large\\bfseries}\n\nIncluding External LaTeX Files: For complex documents, you might want to maintain your LaTeX preamble in a separate .tex file and include it in your R Markdown document.\n\nheader-includes:\n  - \\input{preamble.tex}\n\n\nAdvanced Document Features\nLeveraging LaTeX within R Markdown also allows for the inclusion of advanced document features that are typically challenging to implement, such as conditional text rendering, custom automatic numbering for figures and tables, and intricate mathematical typesetting, which we’ve covered in the previous chapter.\nThe combination of R Markdown and LaTeX offers unparalleled flexibility and power for scientific document creation. By mastering the compilation process and customizing the output, you can produce documents that not only meet the rigorous standards of academic and professional communication but also reflect your personal style and preferences.\n\n\n\nFurther Resources for Mastering LaTeX in R Markdown\nHaving explored the fundamentals and some advanced techniques for integrating LaTeX into R Markdown documents, it’s beneficial to know where to look for further information, tutorials, and community support to continue enhancing your skills. This final chapter provides a curated list of resources, including books, online tutorials, forums, and packages, designed to deepen your understanding and proficiency in using LaTeX with R Markdown for creating professional and sophisticated documents.\n\nBooks\n\n“R Markdown: The Definitive Guide” by Yihui Xie, J.J. Allaire, and Garrett Grolemund. This comprehensive guide provides a thorough introduction to R Markdown, including its integration with LaTeX for producing high-quality documents.\n“The LaTeX Companion” by Frank Mittelbach and Michel Goossens. A detailed reference book for LaTeX users, covering a wide range of topics from basic document formatting to more complex customizations and extensions.\n“Practical R Markdown” by Benjamin Soltoff. This book focuses on the practical aspects of using R Markdown in research and data analysis, with sections dedicated to integrating LaTeX for academic writing.\n\n\n\nOnline Tutorials and Guides\n\nOverleaf’s LaTeX Tutorials: Overleaf offers a comprehensive series of tutorials for LaTeX beginners and advanced users alike, covering everything from basic document structure to complex mathematical typesetting.\nRStudio’s R Markdown Documentation: The official R Markdown website by RStudio provides extensive documentation, tutorials, and galleries of examples to help users harness the full potential of R Markdown, including its LaTeX capabilities.\n\n\n\nCommunity Forums and Support\n\nStack Exchange TeX — LaTeX Stack Exchange: A question and answer site for users of TeX, LaTeX, ConTeXt, and related typesetting systems. It’s an excellent resource for getting help with specific LaTeX questions or issues.\nRStudio Community: The RStudio Community forum is a great place to ask questions and share insights about using R Markdown and LaTeX.\n\n\n\nPackages and Tools\n\ntinytex: An R package that provides a lightweight, portable, and easy-to-maintain LaTeX distribution. It’s specifically designed to simplify the management of LaTeX distributions in R Markdown workflows.\nLaTeX Workshop for Visual Studio Code: For users who prefer Visual Studio Code as their editor, this extension enhances the LaTeX experience with features like build automation, comprehensive linting, and preview.\n\nWhile we’ve covered substantial ground in this guide, the journey to mastering LaTeX in R Markdown is ongoing. The resources listed in this chapter offer pathways to further exploration and mastery. Whether you’re looking to refine your document designs, tackle complex typesetting challenges, or simply stay updated on new packages and features, the LaTeX and R Markdown communities offer a wealth of knowledge and support.\nRemember, the key to proficiency in LaTeX and R Markdown is practice and engagement with the community. Don’t hesitate to experiment with your documents, ask questions, and share your knowledge with others. With these resources at your disposal, you’re well-equipped to take your document creation skills to new heights."
  },
  {
    "objectID": "bi/index.html",
    "href": "bi/index.html",
    "title": "Business intelligence",
    "section": "",
    "text": "Crafting Elegant Scientific Documents in RStudio: A LaTeX and R Markdown Tutorial\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2024\n\n\nNumbers around us\n\n\n\n\n\n\n\n\n\n\n\n\nMastering purrr: From Basic Maps to Functional Magic in R\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nNumbers around us\n\n\n\n\n\n\n\n\n\n\n\n\nThe purrr Package: A Conductor’s Baton for the Tidyverse Orchestra in R\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2024\n\n\nNumbers around us\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "bi/posts/2023-04-13_The-purrr-Package--A-Conductor-s-Baton-for-the-Tidyverse-Orchestra-in-R-57762fd1e4bb.html",
    "href": "bi/posts/2023-04-13_The-purrr-Package--A-Conductor-s-Baton-for-the-Tidyverse-Orchestra-in-R-57762fd1e4bb.html",
    "title": "The purrr Package: A Conductor’s Baton for the Tidyverse Orchestra in R",
    "section": "",
    "text": "The purrr package is a vital player in the tidyverse, an ecosystem of R packages designed to streamline data analysis tasks. As the Swiss Army knife of functional programming in R, purrr provides a versatile toolkit for working with data structures, especially lists and data frames. By simplifying complex operations, it brings clarity and elegance to your code, enabling you to manipulate, transform, and summarize data with ease. Picture purrr as the conductor of an orchestra, harmonizing the different sections of the tidyverse to create a beautiful symphony of data analysis. In this article, we’ll delve into the intricacies of purrr and discover how it can help you harness the full potential of R in your data analysis journey.\n\nUnderstanding purrr: The Functional Programming Paradigm\nTo fully appreciate the purrr package, it’s essential to understand the functional programming paradigm, which serves as the foundation of purrr’s capabilities.\nFunctional programming is a programming approach that treats computation as the evaluation of mathematical functions while avoiding changing state and mutable data. This style of programming emphasizes the use of pure functions, which are functions that, given the same input, will always produce the same output without any side effects. Picture functional programming like a composer, who brings together various instruments, playing their individual parts in perfect harmony, to create a unified and elegant piece of music.\nFunctional programming offers several benefits when working with R, particularly for data analysis. Some of these advantages include:\n\nReadability: Functional programming promotes writing clean and modular code, making it easier for others (and yourself) to understand and maintain the code. Think of it as a well-organized musical score, with each section clearly marked and easy to follow.\nReusability: Pure functions can be easily reused across different parts of your code, as they don’t rely on any external state. This reduces the need to write repetitive code and allows you to create a library of versatile functions, much like a conductor reusing musical motifs throughout a symphony.\nEase of debugging: By minimizing the use of mutable data and global state, functional programming reduces the likelihood of unexpected bugs, making the code more predictable and easier to debug. It’s akin to a conductor being able to isolate and resolve any discordant notes within the orchestra.\nParallel processing: The absence of side effects in functional programming allows for more efficient parallel processing, enabling you to harness the full power of modern multi-core processors. It’s like having multiple conductors working in perfect sync, seamlessly leading the orchestra in harmony.\n\nThe purrr package is designed to work seamlessly with R’s functional programming capabilities. One of its key strengths lies in its ability to apply functions to elements within data structures, such as lists and data frames. The package offers a range of “map” functions that allow you to elegantly iterate over these structures, transforming and manipulating the data as needed. This powerful feature of purrr serves as the conductor’s baton, guiding the flow of your data analysis and helping you create a harmonious and efficient workflow.\nIn the following sections, we will explore purrr’s key functions and demonstrate how they can help you streamline your data analysis process in R.\n\n\nA Closer Look at purrr’s Key Functions\nNow that we have a solid understanding of the functional programming paradigm, let’s dive into some of the key functions that the purrr package offers. These functions, like a conductor’s hand gestures, guide the flow of data through various operations, ensuring an efficient and harmonious analysis.\nmap() and its variants: Turning a caterpillar of code into a butterfly\nThe map() function is the cornerstone of the purrr package, allowing you to apply a function to each element of a list or vector. This versatile function can simplify your code by replacing cumbersome for loops and lapply() calls with a more concise and expressive syntax. The map() function comes in several variants, each tailored to return a specific type of output, such as map_lgl() for logical, map_chr() for character, and map_dbl() for double values. This flexibility enables you to transform your code into a more elegant and streamlined form, much like a caterpillar metamorphosing into a beautiful butterfly.\npmap(): Mastering multiple inputs like juggling balls\nThe pmap() function is designed to handle multiple input lists or vectors, iterating over them in parallel and applying a specified function. This powerful function allows you to juggle multiple inputs effortlessly, enabling complex data manipulation and transformation with ease. Like a skilled juggler, pmap() keeps all the input “balls” in the air, ensuring that they’re processed and combined as intended.\nkeep() and discard(): Handpicking data like sorting apples\nWhen you need to filter data based on specific criteria, purrr’s keep() and discard() functions come to the rescue. keep() retains elements that meet a given condition, while discard() removes elements that meet the condition. These functions let you handpick data elements as if you were sorting apples, keeping the good ones and discarding the bad. With their intuitive syntax and functional programming approach, keep() and discard() make data filtering a breeze.\nreduce(): Folding data like origami\nThe reduce() function in purrr allows you to successively apply a function to elements of a list or vector, effectively “folding” the data like an intricate piece of origami. This function is particularly useful when you need to aggregate data or combine elements in a specific manner. By iteratively applying a specified function, reduce() skillfully folds your data into the desired shape or form.\nsafely(): Handling errors gracefully like a trapeze artist\nIn data analysis, errors and unexpected situations can arise. The safely() function in purrr enables you to handle these scenarios with grace and poise, much like a trapeze artist performing a complex routine. safely() takes a function as input and returns a new function that, when applied, captures any errors and returns them as part of the output, rather than halting the execution. This allows you to identify and address errors without disrupting the flow of your analysis.\nThese key functions, along with many others in the purrr package, provide a powerful toolkit for efficient and harmonious data analysis in R. In the next sections, we’ll explore how to apply these functions to real-life data analysis tasks and demonstrate their practical applications.\n\n\nApplying purrr to Real-Life Data Analysis Tasks\nNow that we’ve explored the key functions of the purrr package, let’s examine how they can be applied to real-life data analysis tasks. By integrating purrr into your workflow, you can master the art of data analysis like a skilled conductor, guiding the flow of data through various operations and producing harmonious results.\nData transformation: Cleaning up a messy room\nData transformation is an essential step in the data analysis process, as real-world data can often be messy and unstructured. Using purrr’s map() functions, you can easily apply cleaning and transformation operations to your data, much like tidying up a cluttered room. For example, you might use map_chr() to extract specific information from text strings, or map_dbl() to convert data types within a data frame. By applying these functions iteratively, you can transform and reshape your data into a more structured and usable format.\nData aggregation: Assembling a puzzle\nIn many cases, you’ll need to aggregate data from multiple sources or perform complex calculations to derive insights. The reduce() function in purrr allows you to combine data elements like puzzle pieces, iteratively applying a function to merge or aggregate data as needed. Whether you’re summing up values, calculating averages, or performing custom aggregations, reduce() can help you assemble the data puzzle and reveal the bigger picture.\nData summarization: Condensing a novel into a short story\nData summarization is the process of distilling large amounts of information into concise, meaningful insights. Using purrr’s functional programming approach, you can create custom summary functions that extract relevant information from your data, much like condensing a novel into a short story. By chaining together map() functions with other tidyverse tools, such as dplyr’s summarize() and mutate() functions, you can generate insightful summaries that highlight the most important aspects of your data.\nIterative operations: Unraveling the threads of data\nMany data analysis tasks require performing iterative operations, such as running simulations, fitting models, or processing data in chunks. With purrr’s pmap() function, you can effortlessly juggle multiple inputs and apply functions across them in parallel. This enables you to unravel the threads of data, revealing patterns and relationships that might otherwise remain hidden. Additionally, by combining purrr’s functions with other R tools, such as parallel processing packages or machine learning libraries, you can further enhance the efficiency and power of your iterative operations.\nIn summary, purrr’s functional programming capabilities enable you to tackle a wide range of data analysis tasks with elegance and efficiency. By integrating purrr into your workflow, you can master the art of data analysis, conducting your data orchestra in perfect harmony.\n\n\nCase Study: Building Models and Creating Visualizations with purrr and Nested Data\nIn R we usually have many function vectorized which mean that for example they can be used on column of dataframe without using loop, apply or map. Purrr’s map functions can of course be used to apply vectorized functions, but is too easy. Let me show you something little bit harder and showing more of purrr’s capabilities.\nIn this case study, we will demonstrate how to use purrr with nested data to build multiple models and create custom visualizations.\nIntroducing the dataset: A collection of diverse species\nImagine we have a dataset containing measurements of various iris species, including sepal length, sepal width, petal length, and petal width, as well as the species classification. Our goal is to create separate linear regression models for each species to predict petal length based on petal width and visualize the results.\nData preparation: Nesting the data like a matryoshka doll\nTo begin, we need to split the dataset by species and create a nested data frame. We can use dplyr’s group_by() and tidyr’s nest() functions for this task:"
  },
  {
    "objectID": "bi/posts/mastering_purrr.html",
    "href": "bi/posts/mastering_purrr.html",
    "title": "Mastering purrr: From Basic Maps to Functional Magic in R",
    "section": "",
    "text": "purrr image\n\n\nWelcome back to the world of purrr! Last time (about a year ago), we spun a metaphorical yarn about the wonders of purrr in R. Today, we’re rolling up our sleeves and diving into a hands-on tutorial. We’re going to explore how purrr makes working with lists and vectors a breeze, transforming and manipulating them like a data wizard.\nWith purrr, you can apply functions to each element of a list or vector, manipulate them, check conditions, and so much more. It’s all about making your data dance to your commands with elegance and efficiency. Ready to unleash some functional magic?\n\nAre map Functions Like apply Functions?\nYou might be wondering, “Aren’t map functions just fancy versions of apply functions?” It’s a fair question! Both map and apply functions help you apply a function to elements in a data structure, but purrr takes it to a whole new level.\nHere’s why purrr and its map functions are worth your attention:\n\nConsistency: purrr functions have a consistent naming scheme, making them easier to learn and remember.\nType Safety: map functions in purrr return outputs of consistent types, reducing unexpected errors.\nIntegration: Seamlessly integrate with other tidyverse packages, making your data wrangling pipeline smoother.\n\nLet’s see a quick comparison:\nlibrary(tidyverse)\n\n# Using lapply (base R)\nnumbers &lt;- list(1, 2, 3, 4, 5)\nsquared_lapply &lt;- lapply(numbers, function(x) x^2)\n\n# Using map (purrr)\nsquared_map &lt;- map(numbers, ~ .x^2)\n\nprint(squared_lapply)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\nprint(squared_map)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\nBoth do the same thing, but purrr’s map function is more readable and concise, especially when paired with the tidyverse syntax.\nHere’s another example with a built-in dataset:\n# Using lapply with a built-in dataset\niris_split &lt;- split(iris, iris$Species)\nmean_sepal_length_lapply &lt;- lapply(iris_split, function(df) mean(df$Sepal.Length))\n\n# Using map with a built-in dataset\nmean_sepal_length_map &lt;- map(iris_split, ~ mean(.x$Sepal.Length))\n\nprint(mean_sepal_length_lapply)\n\n$setosa\n[1] 5.006\n\n$versicolor\n[1] 5.936\n\n$virginica\n[1] 6.588\n\nprint(mean_sepal_length_map)\n\n$setosa\n[1] 5.006\n\n$versicolor\n[1] 5.936\n\n$virginica\n[1] 6.588\nAgain, the purrr version is cleaner and easier to understand at a glance.\nConvinced? Let’s move on to explore simple maps and their variants to see more of purrr’s magic. Ready?\n\n\nSimple Maps and Their Variants\nNow that we know why purrr’s map functions are so cool, let’s dive into some practical examples. The map function family is like a Swiss Army knife for data transformation. It comes in different flavors depending on the type of output you want: logical, integer, character, or double.\nLet’s start with the basic map function:\nlibrary(tidyverse)\n\n# Basic map example\nnumbers &lt;- list(1, 2, 3, 4, 5)\nsquared_numbers &lt;- map(numbers, ~ .x^2)\nsquared_numbers\nEasy, right? Yes, but we have one twist here. Result is returned as list, and we don’t always need list. So now, let’s look at the type-specific variants. These functions ensure that the output is of a specific type, which can help avoid unexpected surprises in your data processing pipeline.\n\nLogical (map_lgl):\n\n# Check if each number is even\nis_even &lt;- map_lgl(numbers, ~ .x %% 2 == 0)\nis_even\n\n[1] FALSE  TRUE FALSE  TRUE FALSE\n\n# it is not list anymore, it is logical vector\n\nInteger (map_int):\n\n# Double each number and return as integers\ndoubled_integers &lt;- map_int(numbers, ~ .x * 2)\ndoubled_integers\n\n[1]  2  4  6  8 10\n\nCharacter (map_chr):\n\n# Convert each number to a string\nnumber_strings &lt;- map_chr(numbers, ~ paste(\"Number\", .x))\nnumber_strings\n\n[1] \"Number 1\" \"Number 2\" \"Number 3\" \"Number 4\" \"Number 5\"\n\nDouble (map_dbl):\n\n# Half each number and return as doubles\nhalved_doubles &lt;- map_dbl(numbers, ~ .x / 2)\nhalved_doubles\n\n[1] 0.5 1.0 1.5 2.0 2.5\nLet’s apply this to a built-in dataset to see it in action:\n# Using map_dbl on the iris dataset to get the mean of each numeric column\niris_means &lt;- iris %&gt;%\n  select(-Species) %&gt;%\n  map_dbl(mean)\niris_means\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \nHere, we’ve calculated the mean of each numeric column in the iris dataset, and the result is a named vector of doubles.\nPretty neat, huh? The map family makes it easy to ensure your data stays in the format you expect.\nReady to see how purrr handles multiple vectors with map2 and pmap?\n\n\nNot Only One Vector: map2 and pmap + Variants\nSo far, we’ve seen how map functions work with a single vector or list. But what if you have multiple vectors and want to apply a function to corresponding elements from each? Enter map2 and pmap.\n\nmap2: This function applies a function to corresponding elements of two vectors or lists.\npmap: This function applies a function to corresponding elements of multiple lists.\n\nLet’s start with map2:\nlibrary(tidyverse)\n\n# Two vectors to work with\nvec1 &lt;- c(1, 2, 3)\nvec2 &lt;- c(4, 5, 6)\n\n# Adding corresponding elements of two vectors\nsum_vecs &lt;- map2(vec1, vec2, ~ .x + .y)\nsum_vecs\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 7\n\n[[3]]\n[1] 9\nHere, map2 takes elements from vec1 and vec2 and adds them together.\nNow, let’s step it up with pmap:\n# Creating a tibble for multiple lists\ndf &lt;- tibble(\n  a = 1:3,\n  b = 4:6,\n  c = 7:9\n)\n\n# Summing corresponding elements of multiple lists\nsum_pmap &lt;- pmap(df, ~ ..1 + ..2 + ..3)\nsum_pmap\n\n[[1]]\n[1] 12\n\n[[2]]\n[1] 15\n\n[[3]]\n[1] 18\nIn this example, pmap takes elements from columns a, b, and c of the tibble and sums them up.\nLook at syntax in those two examples. In map2, we give two vectors or lists, and then we are reffering to them as .x and .y. Further in pmap example we have data.frame, but it can be a list of lists, and we need to refer to them with numbers like ..1, ..2 and ..3 (and more if needed).\n\n\nVariants of map2 and pmap\nJust like map, map2 and pmap have type-specific variants. Let’s see a couple of examples using data structures already defined above:\n\nmap2_dbl:\n\n# Multiplying corresponding elements of two vectors and returning doubles\nproduct_vecs &lt;- map2_dbl(vec1, vec2, ~ .x * .y)\nproduct_vecs\n\n[1]  4 10 18\n\npmap_chr:\n\n# Concatenating corresponding elements of multiple lists into strings\nconcat_pmap &lt;- pmap_chr(df, ~ paste(..1, ..2, ..3, sep = \"-\"))\nconcat_pmap\n\n[1] \"1-4-7\" \"2-5-8\" \"3-6-9\"\nThese variants ensure that your results are of the expected type, just like the basic map variants.\nWith map2 and pmap, you can handle more complex data transformations involving multiple vectors or lists with ease.\nReady to move on and see what lmap and imap can do for you?\n\n\nUsing imap for Indexed Mapping and Conditional Maps with _if and _at\nLet’s combine our exploration of imap with the conditional mapping functions map_if and map_at. These functions give you more control over how and when functions are applied to your data, making your code more precise and expressive.\n\nimap: Indexed Mapping\nThe imap function is a handy tool when you need to include the index or names of elements in your function calls. This is particularly useful for tasks where the position or name of an element influences the operation performed on it.\nHere’s a practical example with a named list:\nlibrary(tidyverse)\n\n# A named list of scores\nnamed_scores &lt;- list(math = 90, science = 85, history = 78)\n\n# Create descriptive strings for each score\nscore_descriptions &lt;- imap(named_scores, ~ paste(.y, \"score is\", .x))\nscore_descriptions\n\n$math\n[1] \"math score is 90\"\n\n$science\n[1] \"science score is 85\"\n\n$history\n[1] \"history score is 78\"\nIn this example:\n\nWe have a named list named_scores with subject scores.\nWe use imap to create a descriptive string for each score that includes the subject name and the score.\n\n\n\nConditional Maps with map_if and map_at\nSometimes, you don’t want to apply a function to all elements of a list or vector — only to those that meet certain conditions. This is where map_if and map_at come into play.\nmap_if: Conditional Mapping\nUse map_if to apply a function to elements that satisfy a specific condition (predicate).\n# Mixed list of numbers and characters\nmixed_list &lt;- list(1, \"a\", 3, \"b\", 5)\n\n# Double only the numeric elements\ndoubled_numbers &lt;- map_if(mixed_list, is.numeric, ~ .x * 2)\ndoubled_numbers\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] \"b\"\n\n[[5]]\n[1] 10\nIn this example:\n\nWe have a mixed list of numbers and characters.\nWe use map_if to double only the numeric elements, leaving the characters unchanged.\n\nmap_at: Specific Element Mapping\nUse map_at to apply a function to specific elements of a list or vector, identified by their indices or names.\n# A named list of mixed types\nspecific_list &lt;- list(a = 1, b = \"hello\", c = 3, d = \"world\")\n\n# Convert only the character elements to uppercase\nuppercase_chars &lt;- map_at(specific_list, c(\"b\", \"d\"), ~ toupper(.x))\nuppercase_chars\n\n$a\n[1] 1\n\n$b\n[1] \"HELLO\"\n\n$c\n[1] 3\n\n$d\n[1] \"WORLD\"\nIn this example:\n\nWe have a named list with mixed types.\nWe use map_at to convert only the specified character elements to uppercase.\n\nCombining imap, map_if, and map_at allows you to handle complex data transformation tasks with precision and clarity. These functions make it easy to tailor your operations to the specific needs of your data.\nShall we move on to the next chapter to explore walk and its friends for side-effect operations?\n\n\n\nMake Something Happen Outside of Data: walk and Its Friends\nSometimes, you want to perform operations that have side effects, like printing, writing to a file, or plotting, rather than returning a transformed list or vector. This is where the walk family of functions comes in handy. These functions are designed to be used for their side effects, as they return NULL.\n\nwalk\nThe basic walk function applies a function to each element of a list or vector and performs actions like printing or saving files.\nlibrary(tidyverse)\n\n# A list of numbers\nnumbers &lt;- list(1, 2, 3, 4, 5)\n\n# Print each number\nwalk(numbers, ~ print(.x))\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\nIn this example, walk prints each element of the numbers list.\n\n\nwalk2\nWhen you have two lists or vectors and you want to perform side-effect operations on their corresponding elements, walk2 is your friend.\n# Two vectors to work with\nvec1 &lt;- c(\"apple\", \"banana\", \"cherry\")\nvec2 &lt;- c(\"red\", \"yellow\", \"dark red\")\n\n# Print each fruit with its color\nwalk2(vec1, vec2, ~ cat(.x, \"is\", .y, \"\\n\"))\n\napple is red \nbanana is yellow \ncherry is dark red \nHere, walk2 prints each fruit with its corresponding color.\n\n\niwalk\niwalk is the side-effect version of imap. It includes the index or names of the elements, which can be useful for logging or debugging.\n# A named list of scores\nnamed_scores &lt;- list(math = 90, science = 85, history = 78)\n\n# Print each subject with its score\niwalk(named_scores, ~ cat(\"The score for\", .y, \"is\", .x, \"\\n\"))\n\nThe score for math is 90 \nThe score for science is 85 \nThe score for history is 78 \nIn this example, iwalk prints each subject name with its corresponding score.\n\n\nPractical Example with Built-in Data\nLet’s use a built-in dataset and perform some side-effect operations. Suppose you want to save plots of each numeric column in the mtcars dataset to separate files.\n# Directory to save plots\ndir.create(\"plots\")\n\n# Save histograms of each numeric column to files\nwalk(names(mtcars), ~ {\n  if (is.numeric(mtcars[[.x]])) {\n    plot_path &lt;- paste0(\"plots/\", .x, \"_histogram.png\")\n    png(plot_path)\n    hist(mtcars[[.x]], main = paste(\"Histogram of\", .x), xlab = .x)\n    dev.off()\n  }\n})\n\n\n\nmtcars histogram\n\n\nIn this example:\n\nWe create a directory called “plots”.\nWe use walk to iterate over the names of the mtcars dataset.\nFor each numeric column, we save a histogram to a PNG file.\n\nThis is a practical demonstration of how walk can be used for side-effect operations such as saving files.\n\n\n\nWhy Do We Need modify Then?\nSometimes you need to tweak elements within a list or vector without completely transforming them. This is where modify functions come in handy. They allow you to make specific changes to elements while preserving the overall structure of your data.\n\nmodify\nThe modify function applies a transformation to each element of a list or vector and returns the modified list or vector.\nlibrary(tidyverse)\n\n# A list of numbers\nnumbers &lt;- list(1, 2, 3, 4, 5)\n\n# Add 10 to each number\nmodified_numbers &lt;- modify(numbers, ~ .x + 10)\nmodified_numbers\n\n[[1]]\n[1] 11\n\n[[2]]\n[1] 12\n\n[[3]]\n[1] 13\n\n[[4]]\n[1] 14\n\n[[5]]\n[1] 15\nIn this example, modify adds 10 to each element of the numbers list.\n\n\nmodify_if\nmodify_if is used to conditionally modify elements that meet a specified condition (predicate).\n# Modify only the even numbers by multiplying them by 2\nmodified_if &lt;- modify_if(numbers, ~ .x %% 2 == 0, ~ .x * 2)\nmodified_if\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 5\nHere, modify_if multiplies only the even numbers by 2.\n\n\nmodify_at\nmodify_at allows you to specify which elements to modify based on their indices or names.\n# A named list of mixed types\nnamed_list &lt;- list(a = 1, b = \"hello\", c = 3, d = \"world\")\n\n# Convert only the specified elements to uppercase\nmodified_at &lt;- modify_at(named_list, c(\"b\", \"d\"), ~ toupper(.x))\nmodified_at\n\n$a\n[1] 1\n\n$b\n[1] \"HELLO\"\n\n$c\n[1] 3\n\n$d\n[1] \"WORLD\"\nIn this example, modify_at converts the specified character elements to uppercase.\n\n\nmodify with Built-in Dataset\nLet’s use the iris dataset to demonstrate how modify functions can be applied in a practical scenario. Suppose we want to normalize numeric columns by dividing each value by the maximum value in its column.\n# Normalizing numeric columns in the iris dataset\nnormalized_iris &lt;- iris %&gt;%\n  modify_at(vars(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width), \n            ~ .x / max(.x))\n\nhead(normalized_iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1    0.6455696   0.7954545    0.2028986        0.08  setosa\n2    0.6202532   0.6818182    0.2028986        0.08  setosa\n3    0.5949367   0.7272727    0.1884058        0.08  setosa\n4    0.5822785   0.7045455    0.2173913        0.08  setosa\n5    0.6329114   0.8181818    0.2028986        0.08  setosa\n6    0.6835443   0.8863636    0.2463768        0.16  setosa\n\nhead(iris)\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\nIn this example:\n\nWe use modify_at to specify the numeric columns of the iris dataset.\nEach value in these columns is divided by the maximum value in its respective column, normalizing the data.\n\nmodify functions offer a powerful way to make targeted changes to your data, providing flexibility and control.\n\n\n\nPredicates: Does Data Satisfy Our Assumptions? every, some, and none\nWhen working with data, it’s often necessary to check if certain conditions hold across elements in a list or vector. This is where predicate functions like every, some, and none come in handy. These functions help you verify whether elements meet specified criteria, making your data validation tasks easier and more expressive.\n\nevery\nThe every function checks if all elements in a list or vector satisfy a given predicate. If all elements meet the condition, it returns TRUE; otherwise, it returns FALSE.\nlibrary(tidyverse)\n\n# A list of numbers\nnumbers &lt;- list(2, 4, 6, 8)\n\n# Check if all numbers are even\nall_even &lt;- every(numbers, ~ .x %% 2 == 0)\nall_even\n\n[1] TRUE\nIn this example, every checks if all elements in the numbers list are even.\n\n\nsome\nThe some function checks if at least one element in a list or vector satisfies a given predicate. If any element meets the condition, it returns TRUE; otherwise, it returns FALSE.\n# Check if any number is greater than 5\nany_greater_than_five &lt;- some(numbers, ~ .x &gt; 5)\nany_greater_than_five\n\n[1] TRUE\nHere, some checks if any element in the numbers list is greater than 5.\n\n\nnone\nThe none function checks if no elements in a list or vector satisfy a given predicate. If no elements meet the condition, it returns TRUE; otherwise, it returns FALSE.\n# Check if no number is odd\nnone_odd &lt;- none(numbers, ~ .x %% 2 != 0)\nnone_odd\n\n[1] TRUE\nIn this example, none checks if no elements in the numbers list are odd.\n\n\nPractical Example with Built-in Dataset\nLet’s use the mtcars dataset to demonstrate how these predicate functions can be applied in a practical scenario. Suppose we want to check various conditions on the columns of this dataset.\n# Check if all cars have more than 10 miles per gallon (mpg)\nall_mpg_above_10 &lt;- mtcars %&gt;%\n  select(mpg) %&gt;%\n  map_lgl(~ every(.x, ~ .x &gt; 10))\nall_mpg_above_10\n\nmpg\nTRUE\n\n# Check if some cars have more than 150 horsepower (hp)\nsome_hp_above_150 &lt;- mtcars %&gt;%\n  select(hp) %&gt;%\n  map_lgl(~ some(.x, ~ .x &gt; 150))\nsome_hp_above_150\n\nhp\nTRUE\n\n# Check if no car has more than 8 cylinders\nnone_cyl_above_8 &lt;- mtcars %&gt;%\n  select(cyl) %&gt;%\n  map_lgl(~ none(.x, ~ .x &gt; 8))\nnone_cyl_above_8\n\ncyl\nTRUE\nIn this example:\n\nWe check if all cars in the mtcars dataset have more than 10 mpg using every.\nWe check if some cars have more than 150 horsepower using some.\nWe check if no car has more than 8 cylinders using none.\n\nThese predicate functions provide a straightforward way to validate your data against specific conditions, making your analysis more robust.\n\n\n\nWhat If Not: keep and discard\nWhen you’re working with lists or vectors, you often need to filter elements based on certain conditions. The keep and discard functions from purrr are designed for this purpose. They allow you to retain or remove elements that meet specified criteria, making it easy to clean and subset your data.\n\nkeep\nThe keep function retains elements that satisfy a given predicate. If an element meets the condition, it is kept; otherwise, it is removed.\nlibrary(tidyverse)\n\n# A list of mixed numbers\nnumbers &lt;- list(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n# Keep only the even numbers\neven_numbers &lt;- keep(numbers, ~ .x %% 2 == 0)\neven_numbers\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\nIn this example, keep retains only the even numbers from the numbers list.\n\n\ndiscard\nThe discard function removes elements that satisfy a given predicate. If an element meets the condition, it is discarded; otherwise, it is kept.\n# Discard the even numbers\nodd_numbers &lt;- discard(numbers, ~ .x %% 2 == 0)\nodd_numbers\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 3\n\n[[3]]\n[1] 5\n\n[[4]]\n[1] 7\n\n[[5]]\n[1] 9\nHere, discard removes the even numbers, leaving only the odd numbers in the numbers list.\n\n\n\nPractical Example with Built-in Dataset\nLet’s use the iris dataset to demonstrate how keep and discard can be applied in a practical scenario. Suppose we want to filter rows based on specific conditions for the Sepal.Length column.\nlibrary(tidyverse)\n\n# Keep rows where Sepal.Length is greater than 5.0\niris_keep &lt;- iris %&gt;%\n  split(1:nrow(.)) %&gt;%\n  keep(~ .x$Sepal.Length &gt; 5.0) %&gt;%\n  bind_rows()\nhead(iris_keep)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          5.4         3.9          1.7         0.4  setosa\n3          5.4         3.7          1.5         0.2  setosa\n4          5.8         4.0          1.2         0.2  setosa\n5          5.7         4.4          1.5         0.4  setosa\n6          5.4         3.9          1.3         0.4  setosa\n\n# Discard rows where Sepal.Length is less than or equal to 5.0\niris_discard &lt;- iris %&gt;%\n  split(1:nrow(.)) %&gt;%\n  discard(~ .x$Sepal.Length &lt;= 5.0) %&gt;%\n  bind_rows()\nhead(iris_discard)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          5.4         3.9          1.7         0.4  setosa\n3          5.4         3.7          1.5         0.2  setosa\n4          5.8         4.0          1.2         0.2  setosa\n5          5.7         4.4          1.5         0.4  setosa\n6          5.4         3.9          1.3         0.4  setosa\nIn this example:\n\nWe split the iris dataset into a list of rows.\nWe apply keep to retain rows where Sepal.Length is greater than 5.0.\nWe apply discard to remove rows where Sepal.Length is less than or equal to 5.0.\nFinally, we use bind_rows() to combine the list back into a data frame.\n\n\nCombining keep and discard with mtcars\nSimilarly, let’s fix the mtcars example:\n# Keep cars with mpg greater than 20 and discard cars with hp less than 100\nfiltered_cars &lt;- mtcars %&gt;%\n  split(1:nrow(.)) %&gt;%\n  keep(~ .x$mpg &gt; 20) %&gt;%\n  discard(~ .x$hp &lt; 100) %&gt;%\n  bind_rows()\n\nfiltered_cars\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4     4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4     4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3     1\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5     2\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4     2\nIn this combined example:\n\nWe split the mtcars dataset into a list of rows.\nWe use keep to retain cars with mpg greater than 20.\nWe use discard to remove cars with hp less than 100.\nWe combine the filtered list back into a data frame using bind_rows().\n\n\n\n\nDo Things in Order of List/Vector: accumulate, reduce\nSometimes, you need to perform cumulative or sequential operations on your data. This is where accumulate and reduce come into play. These functions allow you to apply a function iteratively across elements of a list or vector, either accumulating results at each step or reducing the list to a single value.\n\naccumulate\nThe accumulate function applies a function iteratively to the elements of a list or vector and returns a list of intermediate results.\nLet’s start with a simple example:\nlibrary(tidyverse)\n\n# A list of numbers\nnumbers &lt;- list(1, 2, 3, 4, 5)\n\n# Cumulative sum of the numbers\ncumulative_sum &lt;- accumulate(numbers, `+`)\ncumulative_sum\n\n[1]  1  3  6 10 15\n\n\nreduce\nThe reduce function applies a function iteratively to reduce the elements of a list or vector to a single value.\nHere’s a basic example:\n# Sum of the numbers\ntotal_sum &lt;- reduce(numbers, `+`)\ntotal_sum\n\n[1] 15\n\n\nPractical Example with Built-in Dataset\nLet’s use the mtcars dataset to demonstrate how accumulate and reduce can be applied in a practical scenario.\nUsing accumulate with mtcars\nSuppose we want to calculate the cumulative sum of the miles per gallon (mpg) for each car.\n# Cumulative sum of mpg values\ncumulative_mpg &lt;- mtcars %&gt;%\n  pull(mpg) %&gt;%\n  accumulate(`+`)\ncumulative_mpg\n\n[1]  21.0  42.0  64.8  86.2 104.9 123.0 137.3 161.7 184.5 203.7 221.5 237.9 255.2 270.4 280.8 291.2 305.9 338.3 368.7\n[20] 402.6 424.1 439.6 454.8 468.1 487.3 514.6 540.6 571.0 586.8 606.5 621.5 642.9\nIn this example, accumulate gives us a cumulative sum of the mpg values for the cars in the mtcars dataset.\nUsing reduce with mtcars\nNow, let’s say we want to find the product of all mpg values:\n# Product of mpg values\nproduct_mpg &lt;- mtcars %&gt;%\n  pull(mpg) %&gt;%\n  reduce(`*`)\nproduct_mpg\n\n[1] 1.264241e+41\nIn this example, reduce calculates the product of all mpg values in the mtcars dataset.\n\n\n\nDo It Another Way: compose and negate\nCreating flexible and reusable functions is a hallmark of efficient programming. purrr provides tools like compose and negate to help you build and manipulate functions more effectively. These tools allow you to combine multiple functions into one or invert the logic of a predicate function.\n\ncompose\nThe compose function combines multiple functions into a single function that applies them sequentially. This can be incredibly useful for creating pipelines of operations.\nHere’s a basic example:\nlibrary(tidyverse)\n\n# Define some simple functions\nadd1 &lt;- function(x) x + 1\nsquare &lt;- function(x) x * x\n\n# Compose them into a single function\nadd1_and_square &lt;- compose(square, add1)\n\n# Apply the composed function\nresult &lt;- add1_and_square(2)  # (2 + 1)^2 = 9\nresult\n\n[1] 9\nIn this example:\n\nWe define two simple functions: add1 and square.\nWe use compose to create a new function, add1_and_square, which first adds 1 to its input and then squares the result.\nWe apply the composed function to the number 2, yielding 9.\n\n\n\nPractical Example with Built-in Dataset\nLet’s use compose with a more practical example involving the mtcars dataset. Suppose we want to create a function that first scales the horsepower (hp) by 10 and then calculates the logarithm.\n# Define scaling and log functions\nscale_by_10 &lt;- function(x) x * 10\nsafe_log &lt;- safely(log, otherwise = NA)\n\n# Compose them into a single function\nscale_and_log &lt;- compose(safe_log, scale_by_10)\n\n# Apply the composed function to the hp column\nmtcars &lt;- mtcars %&gt;%\n  mutate(log_scaled_hp = map_dbl(hp, ~ scale_and_log(.x)$result))\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb log_scaled_hp\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4     4      7.003065\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4     4      7.003065\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4     1      6.835185\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3     1      7.003065\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3     2      7.467371\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3     1      6.956545\nIn this example:\n\nWe define two functions: scale_by_10 and safe_log.\nWe compose these functions into scale_and_log.\nWe apply the composed function to the hp column of the mtcars dataset and add the results as a new column.\n\n\n\nnegate\nThe negate function creates a new function that returns the logical negation of a predicate function. This is useful when you want to invert the logic of a condition.\nHere’s a simple example:\n# Define a simple predicate function\nis_even &lt;- function(x) x %% 2 == 0\n\n# Negate the predicate function\nis_odd &lt;- negate(is_even)\n\n# Apply the negated function\nresults &lt;- map_lgl(1:10, is_odd)\nresults\n\n [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\nIn this example:\n\nWe define a predicate function is_even to check if a number is even.\nWe use negate to create a new function is_odd that returns the opposite result.\nWe apply is_odd to the numbers 1 through 10.\n\n\n\nPractical Example with Built-in Dataset\nLet’s use negate in a practical scenario with the iris dataset. Suppose we want to filter out rows where the Sepal.Length is not greater than 5.0.\n# Define a predicate function\nis_long_sepal &lt;- function(x) x &gt; 5.0\n\n# Negate the predicate function\nis_not_long_sepal &lt;- negate(is_long_sepal)\n\n# Filter out rows where Sepal.Length is not greater than 5.0\niris_filtered &lt;- iris %&gt;%\n  split(1:nrow(.)) %&gt;%\n  discard(~ is_not_long_sepal(.x$Sepal.Length)) %&gt;%\n  bind_rows()\n\nhead(iris_filtered)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          5.4         3.9          1.7         0.4  setosa\n3          5.4         3.7          1.5         0.2  setosa\n4          5.8         4.0          1.2         0.2  setosa\n5          5.7         4.4          1.5         0.4  setosa\n6          5.4         3.9          1.3         0.4  setosa\nIn this example:\n\nWe define a predicate function is_long_sepal to check if Sepal.Length is greater than 5.0.\nWe use negate to create a new function is_not_long_sepal that returns the opposite result.\nWe use discard to remove rows where Sepal.Length is not greater than 5.0, then combine the filtered list back into a data frame.\n\nWith compose and negate, you can create more flexible and powerful functions, allowing for more concise and readable code.\n\n\n\nConclusion\nCongratulations! You’ve journeyed through the world of purrr, mastering a wide array of functions and techniques to manipulate and transform your data. From basic mapping to creating powerful function compositions, purrr equips you with tools to make your data wrangling tasks more efficient and expressive.\nWhether you’re applying functions conditionally, dealing with side effects, or validating your data, purrr has you covered. Keep exploring and experimenting with these functions to unlock the full potential of functional programming in R.\n\n\nGift for patient readers\nI decided to give you some useful, yet not trivial use cases of purrr functions.\n\nDefine list of function to apply on data\napply_funs &lt;- function(x, ...) purrr::map_dbl(list(...), ~ .x(x))\nWant to apply multiple functions to a single vector and get a tidy result? Meet apply_funs, your new best friend! This nifty little function takes a value and a bunch of functions, then maps each function to the vector, returning the results as a neat vector.\nLet’s break it down:\n\nx: The value you want to transform.\n...: A bunch of functions you want to apply to x.\npurrr::map_dbl: Maps each function in the list to x and returns the results as a vector of doubles.\n\nSuppose that you want to apply 3 summary functions on vector of numbers. Here’s how you can do it:\nnumber &lt;- 1:48\n\nresults &lt;- apply_funs(number, mean, median, sd)\nresults\n\n[1] 24.5 24.5 14.0\n\n\nUsing pmap as equivalent of Python’s zip\nSometimes you need to zip two tables or columns together. In Python there is zip function for it, but we do not have twin function in R, unless you use pmap. I will not make it longer, so check it out in one of my previous articles.\n\n\nRendering parameterized RMarkdown reports\nAssuming that you have kind of report you use for each salesperson, there is possibility, that you are changing parameters manually to generate report for person X, for date range Y, for product Z. Why not prepare lists of people, time range, and list of products, and then based on them generate series of reports by one click only."
  },
  {
    "objectID": "ds/index.html",
    "href": "ds/index.html",
    "title": "Data Science",
    "section": "",
    "text": "This webpage will be mainly about R, Python and SQL"
  }
]